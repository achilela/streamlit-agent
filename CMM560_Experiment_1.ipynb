{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achilela/streamlit-agent/blob/main/CMM560_Experiment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Workflow**\n",
        "\n",
        "Set Google Colab Runtime type to GPU, check if GPU is being used with !nvidia-smi command.\n",
        "\n",
        "1. Load the SURFACE dataset for classification and split it into train and test sets\n",
        "   * Define paths to the datasets, including the path to the tumor and\n",
        "   * Display a random image each from the training and test set\n",
        "   * Convert class names (surface-positive, surface-negative) to numerical labels\n",
        "   * Display two images with their class names and integers labels\n",
        "\n",
        "2. Load a image processor to process images\n",
        "   * Apply data normalization\n",
        "   * Convert images into tensor\n",
        "\n",
        "3.  Apply data augmentation strategies\n",
        "    * Write a function to apply random flip/rotate augmentations to train, test, and validate data\n",
        "\n",
        "4. Choose any two of the non-neural network classifiers from the list below:\n",
        "\n",
        "\n",
        "   *   **Support Vector Machines (SVM)**: SVMs find a hyperplane that best separates data points into different classes. They work well for both linear and non-linear problems.\n",
        "   * **Decision Trees and Random Forests**: Decision trees split data based on\n",
        "   feature values to create a tree-like structure. Random forests combine multiple decision trees to improve accuracy and reduce overfitting.\n",
        "   * **Naive Bayes Classifier (NB)**: NB is based on Bayes' theorem and assumes that features are conditionally independent. It's particularly useful for text classification and spam filtering.\n",
        "   * **K-Nearest Neighbors (KNN)**: KNN classifies data points based on the majority class of their nearest neighbors. It's simple but effective for both regression and classification tasks.\n",
        "   * **Ensemble methods (e.g., AdaBoost, Gradient Boosting)**: These combine multiple base classifiers to create a stronger model. AdaBoost and Gradient Boosting are popular ensemble techniques.\n",
        "\n",
        "5. Implement classification accuracy metric\n",
        "    * Write a function to compute module accuracy by computing predictions and ground truth labels as well as reporting the results in terms of precision, recall, f1-score runtime, ROC and a confusion-matrix\n"
      ],
      "metadata": {
        "id": "9GyCPN2PPigB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "6WdbT6POOEMR",
        "outputId": "fffd38a1-587c-4280-f683-aa72b2df5169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul 23 16:31:05 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY2l--4etrY_"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDSmrG6VwYGi",
        "outputId": "5945d6d9-880e-4d7e-c4d2-0d7b69b747dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1.   Define paths to the datasets, including the path to the SURFACE and UNDERWATER\n",
        "\n",
        "2.   Display a random image each from the training and test set\n",
        "\n",
        "3.   Convert class names (positive, negative) to numerical labels\n",
        "\n",
        "4.   Display two images with their class names and integers labels\n"
      ],
      "metadata": {
        "id": "8g4OUpW5R6L4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Choose at least three non-neural classifiers from the list above and for each of the classifier:\n",
        "   * build a code to classify the images into Positive or Negative\n",
        "   * provide code benchmark to report the results of all chosen three models using precision, recall and F1-score\n",
        "   * provide a reflection around which one of the best models and cost effective justifications on the case and possible implementations\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VokbrLZdGo_h"
      }
    },
    {
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Define the dataset paths\n",
        "train_dir = '/content/drive/MyDrive/data/Surface/train'\n",
        "test_dir = '/content/drive/MyDrive/data/Surface/test'\n",
        "\n",
        "# Function to load images and labels\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for class_name in os.listdir(folder):\n",
        "        class_folder = os.path.join(folder, class_name)\n",
        "        if os.path.isdir(class_folder):\n",
        "            for filename in os.listdir(class_folder):\n",
        "                img_path = os.path.join(class_folder, filename)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.resize(img, (256, 256))  # Resize image to 256x256\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
        "                    images.append(img.flatten())  # Flatten the image\n",
        "                    labels.append(class_name)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load training and test data\n",
        "train_images, train_labels = load_images_from_folder(train_dir)\n",
        "test_images, test_labels = load_images_from_folder(test_dir)\n",
        "\n",
        "# Split the training data into a training and validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "test_images = scaler.transform(test_images)\n",
        "\n",
        "# Train and evaluate SVM classifier\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "val_predictions_svm = svm_classifier.predict(X_val)\n",
        "test_predictions_svm = svm_classifier.predict(test_images)\n",
        "print(\"SVM Validation Accuracy:\", accuracy_score(y_val, val_predictions_svm))\n",
        "print(\"SVM Validation Classification Report:\\n\", classification_report(y_val, val_predictions_svm))\n",
        "print(\"SVM Test Accuracy:\", accuracy_score(test_labels, test_predictions_svm))\n",
        "print(\"SVM Test Classification Report:\\n\", classification_report(test_labels, test_predictions_svm))\n",
        "\n",
        "# Train and evaluate RandomForest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "val_predictions_rf = rf_classifier.predict(X_val)\n",
        "test_predictions_rf = rf_classifier.predict(test_images)\n",
        "print(\"RandomForest Validation Accuracy:\", accuracy_score(y_val, val_predictions_rf))\n",
        "print(\"RandomForest Validation Classification Report:\\n\", classification_report(y_val, val_predictions_rf))\n",
        "print(\"RandomForest Test Accuracy:\", accuracy_score(test_labels, test_predictions_rf))\n",
        "print(\"RandomForest Test Classification Report:\\n\", classification_report(test_labels, test_predictions_rf))\n",
        "\n",
        "# Train and evaluate NaiveBayes classifier\n",
        "nb_classifier = GaussianNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "val_predictions_nb = nb_classifier.predict(X_val)\n",
        "test_predictions_nb = nb_classifier.predict(test_images)\n",
        "print(\"NaiveBayes Validation Accuracy:\", accuracy_score(y_val, val_predictions_nb))\n",
        "print(\"NaiveBayes Validation Classification Report:\\n\", classification_report(y_val, val_predictions_nb))\n",
        "print(\"NaiveBayes Test Accuracy:\", accuracy_score(test_labels, test_predictions_nb))\n",
        "print(\"NaiveBayes Test Classification Report:\\n\", classification_report(test_labels, test_predictions_nb))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "KPv7y9oUytHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LCN4uDdN65lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_scores = cross_val_score(svm_classifier, train_images, train_labels, cv=5)\n",
        "print(\"SVM 5-Fold Cross-Validation Scores:\", svm_scores)\n",
        "print(\"SVM 5-Fold Cross-Validation Mean Accuracy:\", np.mean(svm_scores))"
      ],
      "metadata": {
        "id": "byqQLZOm6_Vk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1581388d-aa91-4886-c430-396f4065f545"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM 5-Fold Cross-Validation Scores: [0.84745763 0.85875706 0.84745763 0.8700565  0.83050847]\n",
            "SVM 5-Fold Cross-Validation Mean Accuracy: 0.8508474576271187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_scores = cross_val_score(rf_classifier, train_images, train_labels, cv=5)\n",
        "print(\"RandomForest 5-Fold Cross-Validation Scores:\", rf_scores)\n",
        "print(\"RandomForest 5-Fold Cross-Validation Mean Accuracy:\", np.mean(rf_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXX2rVvf8UUe",
        "outputId": "4082389d-fd00-4b6e-92a7-8795112ec610"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest 5-Fold Cross-Validation Scores: [0.88700565 0.8700565  0.88700565 0.89265537 0.89830508]\n",
            "RandomForest 5-Fold Cross-Validation Mean Accuracy: 0.8870056497175142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classifier = GaussianNB()\n",
        "nb_scores = cross_val_score(nb_classifier, train_images, train_labels, cv=5)\n",
        "print(\"NaiveBayes 5-Fold Cross-Validation Scores:\", nb_scores)\n",
        "print(\"NaiveBayes 5-Fold Cross-Validation Mean Accuracy:\", np.mean(nb_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FSds1Ot8W6V",
        "outputId": "a00b48a3-6c76-4def-e0d4-fdcd64141635"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaiveBayes 5-Fold Cross-Validation Scores: [0.82485876 0.73446328 0.64971751 0.73446328 0.61581921]\n",
            "NaiveBayes 5-Fold Cross-Validation Mean Accuracy: 0.711864406779661\n"
          ]
        }
      ]
    }
  ]
}